# CVPR-2024-Speech_Audio_Music-Papers
A curated collections of papers related to speech, audio and music in CVPR 2024.

## üóûÔ∏è papers and posters

# Speech

* [Emotional Speech-driven 3D Body Animation via Disentangled Latent Diffusion](https://openaccess.thecvf.com/content/CVPR2024/papers/Chhatre_Emotional_Speech-driven_3D_Body_Animation_via_Disentangled_Latent_Diffusion_CVPR_2024_paper.pdf) Chhatre, Kiran and Danƒõƒçek, Radek and Athanasiou, Nikos and Becherini, Giorgio and Peters, Christopher and Black, Michael J. and Bolkart, Timo [[code]](https://github.com/kiranchhatre/amuse)
* [ES¬≥: Evolving Self-Supervised Learning of Robust Audio-Visual Speech Representations](https://openaccess.thecvf.com/content/CVPR2024/papers/Zhang_ES3_Evolving_Self-Supervised_Learning_of_Robust_Audio-Visual_Speech_Representations_CVPR_2024_paper.pdf) Yuanhang, Zhang and Shuang, Yang and Shiguang, Shan and Xilin, Chen
* [Probabilistic Speech-Driven 3D Facial Motion Synthesis: New Benchmarks Methods and Applications](https://openaccess.thecvf.com/content/CVPR2024/papers/Yang_Probabilistic_Speech-Driven_3D_Facial_Motion_Synthesis_New_Benchmarks_Methods_and_CVPR_2024_paper.pdf) Karren D. Yang and Anurag, Ranjan and Jen-Hao Rick Chang and Raviteja, Vemulapalli and Oncel, Tuzel
* [DiffSHEG: A Diffusion-Based Approach for Real-Time Speech-driven Holistic 3D Expression and Gesture Generation](https://openaccess.thecvf.com/content/CVPR2024/papers/Chen_DiffSHEG_A_Diffusion-Based_Approach_for_Real-Time_Speech-driven_Holistic_3D_Expression_CVPR_2024_paper.pdf) Junming Chen, Yunfei Liu, Jianan, Wang and Ailing, Zeng and Yu, Li and Qifeng, Chen [[code]](https://github.com/JeremyCJM/DiffSHEG)
